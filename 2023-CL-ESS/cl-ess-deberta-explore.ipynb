{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":53482,"databundleVersionId":6201832,"sourceType":"competition"}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-15T08:19:44.838166Z","iopub.execute_input":"2023-09-15T08:19:44.839046Z","iopub.status.idle":"2023-09-15T08:19:45.220735Z","shell.execute_reply.started":"2023-09-15T08:19:44.839013Z","shell.execute_reply":"2023-09-15T08:19:45.219775Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/commonlit-evaluate-student-summaries/sample_submission.csv\n/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv\n/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv\n/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv\n/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"input_path = \"/kaggle/input/commonlit-evaluate-student-summaries/\"\ndf_train_pro_file = pd.read_csv(input_path + 'prompts_train.csv')\ndf_train_sum_file = pd.read_csv(input_path + 'summaries_train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:19:45.223011Z","iopub.execute_input":"2023-09-15T08:19:45.223509Z","iopub.status.idle":"2023-09-15T08:19:45.343505Z","shell.execute_reply.started":"2023-09-15T08:19:45.223471Z","shell.execute_reply":"2023-09-15T08:19:45.342424Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nprint(torch.cuda.is_available())\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:19:45.345086Z","iopub.execute_input":"2023-09-15T08:19:45.345785Z","iopub.status.idle":"2023-09-15T08:19:48.509072Z","shell.execute_reply.started":"2023-09-15T08:19:45.345749Z","shell.execute_reply":"2023-09-15T08:19:48.507987Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Creating a Dataset","metadata":{}},{"cell_type":"code","source":"from sklearn import set_config\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer\n\ndef prepare_data(df_prompts, df_summaries):\n    set_config(transform_output=\"pandas\")\n    scaler = ColumnTransformer([(\"scaled\", StandardScaler(), ['content', 'wording'])], remainder='passthrough')\n    df_summaries = scaler.fit_transform(df_summaries)\n    d = {}\n    for c in df_summaries.columns:\n        if c.startswith('scaled__'):\n            d[c] = c[8:]\n        elif c.startswith('remainder__'):\n            d[c] = c[11:]\n    df_summaries = df_summaries.rename(columns = d)\n    df_merged = pd.merge(df_prompts, df_summaries, how='left', on='prompt_id')\n    \n    # TODO need some string cleaning?\n    return df_merged","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:19:48.512259Z","iopub.execute_input":"2023-09-15T08:19:48.513092Z","iopub.status.idle":"2023-09-15T08:19:48.951960Z","shell.execute_reply.started":"2023-09-15T08:19:48.513055Z","shell.execute_reply":"2023-09-15T08:19:48.950884Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"df = prepare_data(df_train_pro_file, df_train_sum_file)\ndf.sample(3)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:19:48.953388Z","iopub.execute_input":"2023-09-15T08:19:48.954171Z","iopub.status.idle":"2023-09-15T08:19:49.004077Z","shell.execute_reply.started":"2023-09-15T08:19:48.954139Z","shell.execute_reply":"2023-09-15T08:19:49.002876Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"     prompt_id                                    prompt_question  \\\n5263    ebad26  Summarize the various ways the factory would u...   \n6856    ebad26  Summarize the various ways the factory would u...   \n3506    3b9047  In complete sentences, summarize the structure...   \n\n                   prompt_title  \\\n5263    Excerpt from The Jungle   \n6856    Excerpt from The Jungle   \n3506  Egyptian Social Structure   \n\n                                            prompt_text   content   wording  \\\n5263  With one member trimming beef in a cannery, an...  1.383675  0.308263   \n6856  With one member trimming beef in a cannery, an...  0.872908 -0.340020   \n3506  Egyptian society was structured like a pyramid... -0.926129 -1.434231   \n\n        student_id                                               text  \n5263  0dc8cd731fe7  The different ways the factories would use and...  \n6856  d86654b16974  They used many wild methods of masking the sme...  \n3506  ba5f4e4383f4  The structure of the ancient egyptian system  ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_id</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n      <th>content</th>\n      <th>wording</th>\n      <th>student_id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5263</th>\n      <td>ebad26</td>\n      <td>Summarize the various ways the factory would u...</td>\n      <td>Excerpt from The Jungle</td>\n      <td>With one member trimming beef in a cannery, an...</td>\n      <td>1.383675</td>\n      <td>0.308263</td>\n      <td>0dc8cd731fe7</td>\n      <td>The different ways the factories would use and...</td>\n    </tr>\n    <tr>\n      <th>6856</th>\n      <td>ebad26</td>\n      <td>Summarize the various ways the factory would u...</td>\n      <td>Excerpt from The Jungle</td>\n      <td>With one member trimming beef in a cannery, an...</td>\n      <td>0.872908</td>\n      <td>-0.340020</td>\n      <td>d86654b16974</td>\n      <td>They used many wild methods of masking the sme...</td>\n    </tr>\n    <tr>\n      <th>3506</th>\n      <td>3b9047</td>\n      <td>In complete sentences, summarize the structure...</td>\n      <td>Egyptian Social Structure</td>\n      <td>Egyptian society was structured like a pyramid...</td>\n      <td>-0.926129</td>\n      <td>-1.434231</td>\n      <td>ba5f4e4383f4</td>\n      <td>The structure of the ancient egyptian system  ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:19:49.005851Z","iopub.execute_input":"2023-09-15T08:19:49.006276Z","iopub.status.idle":"2023-09-15T08:19:49.026914Z","shell.execute_reply.started":"2023-09-15T08:19:49.006238Z","shell.execute_reply":"2023-09-15T08:19:49.025719Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"            content       wording\ncount  7.165000e+03  7.165000e+03\nmean   7.933485e-18  2.380045e-17\nstd    1.000070e+00  1.000070e+00\nmin   -1.643519e+00 -1.833577e+00\n25%   -7.519837e-01 -7.815319e-01\n50%   -7.566950e-02 -1.804831e-02\n75%    4.930662e-01  5.472181e-01\nmax    3.751981e+00  4.221879e+00","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>wording</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>7.165000e+03</td>\n      <td>7.165000e+03</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>7.933485e-18</td>\n      <td>2.380045e-17</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.000070e+00</td>\n      <td>1.000070e+00</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-1.643519e+00</td>\n      <td>-1.833577e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-7.519837e-01</td>\n      <td>-7.815319e-01</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-7.566950e-02</td>\n      <td>-1.804831e-02</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4.930662e-01</td>\n      <td>5.472181e-01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3.751981e+00</td>\n      <td>4.221879e+00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import Dataset\n\ndf = df[['text', 'content']]\nds = Dataset.from_pandas(df)\nds = ds.train_test_split(test_size=0.1, shuffle=True) # TODO stratify_by_column=\"prompt_id\",  does not work!\n#ds = ds.remove_columns(['prompt_id', 'prompt_question', 'prompt_title', 'prompt_text','student_id', 'wording'])\nds = ds.rename_column(\"content\", \"labels\") # because the model expect a field beginning with label\nds","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:19:49.028581Z","iopub.execute_input":"2023-09-15T08:19:49.028983Z","iopub.status.idle":"2023-09-15T08:19:50.078599Z","shell.execute_reply.started":"2023-09-15T08:19:49.028947Z","shell.execute_reply":"2023-09-15T08:19:50.077594Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'labels'],\n        num_rows: 6448\n    })\n    test: Dataset({\n        features: ['text', 'labels'],\n        num_rows: 717\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# TODO splits for CV","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:19:50.079967Z","iopub.execute_input":"2023-09-15T08:19:50.080466Z","iopub.status.idle":"2023-09-15T08:19:50.087813Z","shell.execute_reply.started":"2023-09-15T08:19:50.080437Z","shell.execute_reply":"2023-09-15T08:19:50.086671Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"ds[\"train\"][3]","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:19:50.089942Z","iopub.execute_input":"2023-09-15T08:19:50.090363Z","iopub.status.idle":"2023-09-15T08:19:50.099180Z","shell.execute_reply.started":"2023-09-15T08:19:50.090329Z","shell.execute_reply":"2023-09-15T08:19:50.098029Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'text': 'Three elements of an ideal tragedy would include death or multiple deaths, a single issue plot, and it should induce pity and fear into the audience.',\n 'labels': -0.9978115162295333}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Creating metrics","metadata":{}},{"cell_type":"code","source":"def get_MCRMSE_score(eval_pred):\n    # columnwise root mean squared error:\n    preds, labels = eval_pred\n         \n    by_column = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n    mcrmse = np.mean(by_column)\n    return mcrmse\n\nr = (np.array([[0.2, 0.4, 0.2], [1, 0.4, 1]]), np.array([[0.2, 0.2, 0.2], [1, 1, 1]]))\nprint(get_MCRMSE_score(r))","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:19:50.104162Z","iopub.execute_input":"2023-09-15T08:19:50.104438Z","iopub.status.idle":"2023-09-15T08:19:50.112180Z","shell.execute_reply.started":"2023-09-15T08:19:50.104414Z","shell.execute_reply":"2023-09-15T08:19:50.111050Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"0.14907119849998599\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    labels = labels.reshape(-1, 1)\n\n    mse = mean_squared_error(labels, logits)\n    rmse = mean_squared_error(labels, logits, squared=False)\n    mae = mean_absolute_error(labels, logits)\n    r2 = r2_score(labels, logits)\n    smape = 1/len(labels) * np.sum(2 * np.abs(logits-labels) / (np.abs(labels) + np.abs(logits))*100)\n    mcrmse = get_MCRMSE_score(eval_pred)\n    \n    return {\"mcrmse\": mcrmse, \"mse\": mse, \"rmse\": rmse, \"mae\": mae, \"r2\": r2, \"smape\": smape}","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:19:50.113858Z","iopub.execute_input":"2023-09-15T08:19:50.115050Z","iopub.status.idle":"2023-09-15T08:19:50.199673Z","shell.execute_reply.started":"2023-09-15T08:19:50.115016Z","shell.execute_reply":"2023-09-15T08:19:50.198691Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Creating the tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModel, AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-small', use_fast=True)\n\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n\ntokenized = ds.map(tokenize_function, batched=True)\ntokenized = tokenized.with_format(type='torch')\ntokenized","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:19:50.201128Z","iopub.execute_input":"2023-09-15T08:19:50.201579Z","iopub.status.idle":"2023-09-15T08:19:58.239711Z","shell.execute_reply.started":"2023-09-15T08:19:50.201543Z","shell.execute_reply":"2023-09-15T08:19:58.238625Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ea20c86957242e99257b5fb52caa510"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b4e203d1fd746fe92fe7040147a4f2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20777dddc32345ffb5f7bdd40b82c387"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e63a7d5688f241f2a734d043f9ec7a38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a564653b0db4c9baa6cefa3853f4100"}},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 6448\n    })\n    test: Dataset({\n        features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 717\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# checking the tokenizer\nphrase = 'these duties without assistance. The pharaoh appointed a chief minister called a vizier.'\ntokens = tokenizer.encode(phrase, return_tensors='pt', truncation=True, padding=True) #, max_length=10\nprint(tokens)\nprint(tokenizer.decode(tokens[0]))\ntokens_plus = tokenizer.encode_plus(phrase, return_tensors='pt', truncation=True, padding=True)\nprint(tokens_plus)\nprint(tokenizer.decode(tokens_plus.input_ids[0]))","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:19:58.241539Z","iopub.execute_input":"2023-09-15T08:19:58.242199Z","iopub.status.idle":"2023-09-15T08:19:58.298862Z","shell.execute_reply.started":"2023-09-15T08:19:58.242162Z","shell.execute_reply":"2023-09-15T08:19:58.297855Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"name":"stdout","text":"tensor([[    1,   378,  5311,   497,  2472,   260,   279, 72139,  4368,   266,\n          2785,  3931,   650,   266, 32336,  5133,   260,     2]])\n[CLS] these duties without assistance. The pharaoh appointed a chief minister called a vizier.[SEP]\n{'input_ids': tensor([[    1,   378,  5311,   497,  2472,   260,   279, 72139,  4368,   266,\n          2785,  3931,   650,   266, 32336,  5133,   260,     2]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n[CLS] these duties without assistance. The pharaoh appointed a chief minister called a vizier.[SEP]\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\ndata_collator = DataCollatorWithPadding(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:19:58.300486Z","iopub.execute_input":"2023-09-15T08:19:58.301887Z","iopub.status.idle":"2023-09-15T08:20:05.086004Z","shell.execute_reply.started":"2023-09-15T08:19:58.301850Z","shell.execute_reply":"2023-09-15T08:20:05.084973Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Creating the Model","metadata":{}},{"cell_type":"code","source":"# preparing a super small dataset to test\nsmall_train_dataset = tokenized[\"train\"].shuffle().select(range(100))\nsmall_test_dataset = tokenized[\"test\"].shuffle().select(range(100))\nsmall_test_dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:20:05.087397Z","iopub.execute_input":"2023-09-15T08:20:05.088084Z","iopub.status.idle":"2023-09-15T08:20:05.114616Z","shell.execute_reply.started":"2023-09-15T08:20:05.088056Z","shell.execute_reply":"2023-09-15T08:20:05.113696Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 100\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained('microsoft/deberta-v3-small', num_labels=1, problem_type=\"regression\").to(device) # 1 for regression","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:20:05.115969Z","iopub.execute_input":"2023-09-15T08:20:05.116286Z","iopub.status.idle":"2023-09-15T08:20:14.934248Z","shell.execute_reply.started":"2023-09-15T08:20:05.116255Z","shell.execute_reply":"2023-09-15T08:20:14.933139Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/286M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a61381697c714cd2bc204812c749a384"}},"metadata":{}},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\n\ntokens = tokens.to(device)\noutput = model(tokens)\nprint(output) # no loss!\n","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:20:14.936049Z","iopub.execute_input":"2023-09-15T08:20:14.936447Z","iopub.status.idle":"2023-09-15T08:20:16.781981Z","shell.execute_reply.started":"2023-09-15T08:20:14.936412Z","shell.execute_reply":"2023-09-15T08:20:16.780877Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"SequenceClassifierOutput(loss=None, logits=tensor([[0.1474]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir ='/kaggle/working',          \n    num_train_epochs = 3,     \n    per_device_train_batch_size = 20,   \n    per_device_eval_batch_size = 20, \n    #hidden_dropout_prob= 0.0 # 0.005\n    #attention_probs_dropout_prob=0.0 # 0.005\n    weight_decay = 0.021,               \n    learning_rate = 1.5e-5,\n    #logging_dir = './logs',            \n    save_total_limit = 10,\n    #load_best_model_at_end = True,     \n    #metric_for_best_model = 'rmse',    \n    evaluation_strategy = \"epoch\",\n    save_strategy = \"epoch\",\n    #logging_steps = 100,\n    report_to=\"none\",\n) \n\n# TODO review how the batching is done\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=small_train_dataset,\n    eval_dataset=small_test_dataset,\n    compute_metrics=compute_metrics,\n    data_collator=data_collator\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:20:16.783579Z","iopub.execute_input":"2023-09-15T08:20:16.783955Z","iopub.status.idle":"2023-09-15T08:20:16.819290Z","shell.execute_reply.started":"2023-09-15T08:20:16.783921Z","shell.execute_reply":"2023-09-15T08:20:16.818363Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:20:16.820518Z","iopub.execute_input":"2023-09-15T08:20:16.820953Z","iopub.status.idle":"2023-09-15T08:20:44.933522Z","shell.execute_reply.started":"2023-09-15T08:20:16.820921Z","shell.execute_reply":"2023-09-15T08:20:44.932299Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [15/15 00:26, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcrmse</th>\n      <th>Mse</th>\n      <th>Rmse</th>\n      <th>Mae</th>\n      <th>R2</th>\n      <th>Smape</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.215184</td>\n      <td>0.885790</td>\n      <td>1.215184</td>\n      <td>1.102354</td>\n      <td>0.875855</td>\n      <td>0.009206</td>\n      <td>174.516641</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.195469</td>\n      <td>0.879778</td>\n      <td>1.195469</td>\n      <td>1.093375</td>\n      <td>0.863803</td>\n      <td>0.025280</td>\n      <td>176.885879</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>1.188088</td>\n      <td>0.878557</td>\n      <td>1.188088</td>\n      <td>1.089995</td>\n      <td>0.859935</td>\n      <td>0.031299</td>\n      <td>177.389766</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=15, training_loss=1.0552360534667968, metrics={'train_runtime': 27.8268, 'train_samples_per_second': 10.781, 'train_steps_per_second': 0.539, 'total_flos': 39740926464000.0, 'train_loss': 1.0552360534667968, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:20:44.938938Z","iopub.execute_input":"2023-09-15T08:20:44.941541Z","iopub.status.idle":"2023-09-15T08:20:46.648593Z","shell.execute_reply.started":"2023-09-15T08:20:44.941495Z","shell.execute_reply":"2023-09-15T08:20:46.647563Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:01]\n    </div>\n    "},"metadata":{}},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 1.188088059425354,\n 'eval_mcrmse': 0.8785567283630371,\n 'eval_mse': 1.188088059425354,\n 'eval_rmse': 1.0899945497512817,\n 'eval_mae': 0.8599350452423096,\n 'eval_r2': 0.031298664047446745,\n 'eval_smape': 177.389765625,\n 'eval_runtime': 1.6915,\n 'eval_samples_per_second': 59.118,\n 'eval_steps_per_second': 2.956,\n 'epoch': 3.0}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Predicting","metadata":{}},{"cell_type":"code","source":"phrase = ds['test'][24]['text']\nexpected = ds['test'][24]['labels']\nds['test'][15]","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:20:46.652257Z","iopub.execute_input":"2023-09-15T08:20:46.652568Z","iopub.status.idle":"2023-09-15T08:20:46.661164Z","shell.execute_reply.started":"2023-09-15T08:20:46.652534Z","shell.execute_reply":"2023-09-15T08:20:46.660174Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{'text': 'The andent egyptian systam of government is a system that held everyone in place, the pharohs were at the top and the slaves were at the bottom. The way everyone was treated was different the pharohs were treated like royalty, while the slaves were treates like wild animals. ',\n 'labels': -0.07566950483183152}"},"metadata":{}}]},{"cell_type":"code","source":"tokens = tokenizer.encode(phrase, return_tensors='pt', truncation=True, padding=True) \ntokens = tokens.to(device)\noutput = model(tokens)\nprint(output)\nexpected, output.logits","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:20:46.662777Z","iopub.execute_input":"2023-09-15T08:20:46.663457Z","iopub.status.idle":"2023-09-15T08:20:48.090265Z","shell.execute_reply.started":"2023-09-15T08:20:46.663421Z","shell.execute_reply":"2023-09-15T08:20:48.089005Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"SequenceClassifierOutput(loss=None, logits=tensor([[0.0385]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(-0.9261285475237545,\n tensor([[0.0385]], device='cuda:0', grad_fn=<AddmmBackward0>))"},"metadata":{}}]},{"cell_type":"markdown","source":"# Move the model offline","metadata":{}},{"cell_type":"code","source":"save_path = '/kaggle/working/deberta_v3_small_pretrained'\n!mkdir {save_path}\nmodel.save_pretrained(save_path)\ntokenizer.save_pretrained(save_path)\n!ls {save_path}","metadata":{"execution":{"iopub.status.busy":"2023-09-15T08:20:48.092126Z","iopub.execute_input":"2023-09-15T08:20:48.092654Z","iopub.status.idle":"2023-09-15T08:20:53.271481Z","shell.execute_reply.started":"2023-09-15T08:20:48.092603Z","shell.execute_reply":"2023-09-15T08:20:53.270176Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nadded_tokens.json  special_tokens_map.json  tokenizer_config.json\nconfig.json\t   spm.model\npytorch_model.bin  tokenizer.json\n","output_type":"stream"}]}]}